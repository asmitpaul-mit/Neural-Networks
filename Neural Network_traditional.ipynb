{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2738a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35913b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "def relu(Z):\n",
    "    A = np.maximum(0,Z)\n",
    "    \n",
    "    assert(A.shape == Z.shape)\n",
    "    \n",
    "    cache = Z \n",
    "    return A, cache\n",
    "\n",
    "def softmax(Z):\n",
    "    exp_Z = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
    "    A = exp_Z / np.sum(exp_Z, axis=0, keepdims=True)\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "def reluBackward(dA, cache):\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True)\n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "def sigmoidBackward(dA, cache):\n",
    "    Z = cache\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "def softmaxBackward(dA, activation_cache):\n",
    "    Z = activation_cache\n",
    "    dZ = dA\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce77d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeParametersHE(layer_dims):\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters[\"W\" + str(l)] = np.random.randn(layer_dims[l], layer_dims[l - 1])*np.sqrt(2/layer_dims[l-1])\n",
    "        parameters[\"b\" + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbcf3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearForward(A, W, b):\n",
    "    Z = np.dot(W,A)+b\n",
    "    cache = (A, W, b)\n",
    "    return Z, cache\n",
    "\n",
    "def linearActivationForward(A_prev, W, b, activation):\n",
    "    Z, linear_cache = linearForward(A_prev, W, b)\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    elif activation == \"relu\":\n",
    "        A, activation_cache = relu(Z)\n",
    "    elif activation == \"softmax\":\n",
    "        A, activation_cache = softmax(Z)\n",
    "        \n",
    "    cache = (linear_cache, activation_cache)\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "def LModelForward(X, parameters):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters)//2\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        A_prev = A\n",
    "        \n",
    "        A, cache = linearActivationForward(A_prev, parameters[\"W\" + str(l)], parameters[\"b\" + str(l)], activation = 'relu')\n",
    "        caches.append(cache)\n",
    "        \n",
    "    AL, cache = linearActivationForward(A, parameters[\"W\" + str(L)], parameters[\"b\" + str(L)], activation = 'sigmoid')\n",
    "    caches.append(cache)\n",
    "    \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47f494a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    cost = -(np.sum(np.multiply(Y, np.log(AL)) + np.multiply(1 - Y, np.log(1 - AL))))/m\n",
    "    cost = np.squeeze(cost)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f7bdfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearBackward(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    \n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    dW = np.dot(dZ, A_prev.T)/m\n",
    "    db = np.sum(dZ, axis=1, keepdims=True)/m\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "def linearActivationBackward(dA, cache, activation):\n",
    "    linear_cache, activation_cache = cache \n",
    "    \n",
    "    if activation == 'sigmoid':\n",
    "        dZ = sigmoidBackward(dA, activation_cache)\n",
    "    elif activation == 'relu':\n",
    "        dZ = reluBackward(dA, activation_cache)\n",
    "    elif activation == 'softmax':\n",
    "        dZ = softmaxBackward(dA, activation_cache)\n",
    "        \n",
    "    dA_prev, dW, db = linearBackward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "def LModelBackward(AL, Y, caches):\n",
    "    L = len(caches)\n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    \n",
    "    grads = {}\n",
    "    \n",
    "    dAL = -(np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    current_cache = caches[-1]\n",
    "    dA_prev_temp, dW_temp, db_temp = linearActivationBackward(dAL, current_cache, activation = \"sigmoid\")\n",
    "    grads[\"dA\" + str(L - 1)] = dA_prev_temp\n",
    "    grads[\"dW\" + str(L)] = dW_temp\n",
    "    grads[\"db\" + str(L)] = db_temp\n",
    "    \n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linearActivationBackward(grads[\"dA\" + str(l + 1)], current_cache, activation='relu')\n",
    "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74b5405d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateParameters(params, grads, learning_rate):\n",
    "    parameters = copy.deepcopy(params)\n",
    "    L = len(parameters)//2\n",
    "    \n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l + 1)] -= learning_rate*grads[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l + 1)] -= learning_rate*grads[\"db\" + str(l + 1)]\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b294470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_LayeredModel(X, Y, layer_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost = False):\n",
    "    costs = []\n",
    "    \n",
    "    parameters = initializeParametersHE(layer_dims)\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "        AL, caches = LModelForward(X, parameters)\n",
    "        cost = computeCost(AL, Y)\n",
    "        \n",
    "        if print_cost and i % 100 == 0 or i == num_iterations - 1:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "            \n",
    "            Y_pred_train = predict(X, parameters)\n",
    "            accuracy = np.mean(Y_pred_train == np.argmax(Y, axis=0)) * 100\n",
    "            print(\"Train Accuracy after iteration {}: {}%\".format(i, round(accuracy, 5)))\n",
    "            \n",
    "            Y_pred_test = predict(X_test, parameters)\n",
    "            accuracy = np.mean(Y_pred_test == np.argmax(Y_test, axis=0)) * 100\n",
    "            print(\"Test Accuracy after iteration {}: {}%\".format(i, round(accuracy, 5)))\n",
    "        if i % 100 == 0 or i == num_iterations:\n",
    "            costs.append(cost)\n",
    "            \n",
    "        grads = LModelBackward(AL, Y, caches=caches)\n",
    "        parameters = updateParameters(parameters, grads, learning_rate)\n",
    "            \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(f\"Learning rate = {learning_rate}\")\n",
    "    plt.show()\n",
    "            \n",
    "    return parameters, costs\n",
    "\n",
    "def predict(X, parameters):\n",
    "    AL, _ = LModelForward(X, parameters)\n",
    "    return np.argmax(AL, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "227895f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_from_folders(folder_paths):\n",
    "    images = []\n",
    "    \n",
    "    for folder_path in folder_paths:\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                if img is not None:\n",
    "                    images.append(img)\n",
    "                    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc744c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the image array: (8000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "folder_paths = [\"C:\\\\Users\\\\ASMITPAUL\\\\Downloads\\\\train\\\\moe_szyslak\", \n",
    "                \"C:\\\\Users\\\\ASMITPAUL\\\\Downloads\\\\train\\\\ned_flanders\", \n",
    "                \"C:\\\\Users\\\\ASMITPAUL\\\\Downloads\\\\train\\\\principal_skinner\", \n",
    "                \"C:\\\\Users\\\\ASMITPAUL\\\\Downloads\\\\train\\\\bart_simpson\", \n",
    "                \"C:\\\\Users\\\\ASMITPAUL\\\\Downloads\\\\train\\\\charles_montgomery_burns\", \n",
    "                \"C:\\\\Users\\\\ASMITPAUL\\\\Downloads\\\\train\\\\homer_simpson\", \n",
    "                \"C:\\\\Users\\\\ASMITPAUL\\\\Downloads\\\\train\\\\krusty_the_clown\", \n",
    "                \"C:\\\\Users\\\\ASMITPAUL\\\\Downloads\\\\train\\\\lisa_simpson\", \n",
    "                \"C:\\\\Users\\\\ASMITPAUL\\\\Downloads\\\\train\\\\marge_simpson\", \n",
    "                \"C:\\\\Users\\\\ASMITPAUL\\\\Downloads\\\\train\\\\milhouse_van_houten\"]\n",
    "\n",
    "image_matrices = read_images_from_folders(folder_paths)\n",
    "\n",
    "image_array = np.array(image_matrices)\n",
    "\n",
    "print(\"Shape of the image array:\", image_array.shape)\n",
    "\n",
    "X_train = image_array.reshape(image_array.shape[0], -1).T/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62ddd472",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y_train =   [[[1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]]*800 +\n",
    "            [[0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]]*800 +\n",
    "            [[0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]]*800 +\n",
    "            [[0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0]]*800 +\n",
    "            [[0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0]]*800 +\n",
    "            [[0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0]]*800 +\n",
    "            [[0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0]]*800 +\n",
    "            [[0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0]]*800 +\n",
    "            [[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0]]*800 +\n",
    "            [[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]]*800]\n",
    "        \n",
    "Y_train = np.array(Y_train)\n",
    "Y_train = np.squeeze(Y_train)\n",
    "Y_train.shape\n",
    "Y_train = Y_train.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1045a528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the image array: (2000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "folder_paths = [\"C:\\\\Users\\\\ASMITPAUL\\\\Downloads\\\\test\\\\moe_szyslak\", \n",
    "                \"C:\\\\Users\\\\ASMITPAUL\\\\Downloads\\\\test\\\\ned_flanders\", \n",
    "                \"C:\\\\Users\\\\ASMITPAUL\\\\Downloads\\\\test\\\\principal_skinner\", \n",
    "                \"C:\\\\Users\\\\ASMITPAUL\\\\Downloads\\\\test\\\\bart_simpson\", \n",
    "                \"C:\\\\Users\\\\ASMITPAUL\\\\Downloads\\\\test\\\\charles_montgomery_burns\", \n",
    "                \"C:\\\\Users\\\\ASMITPAUL\\\\Downloads\\\\test\\\\homer_simpson\", \n",
    "                \"C:\\\\Users\\\\ASMITPAUL\\\\Downloads\\\\test\\\\krusty_the_clown\", \n",
    "                \"C:\\\\Users\\\\ASMITPAUL\\\\Downloads\\\\test\\\\lisa_simpson\", \n",
    "                \"C:\\\\Users\\\\ASMITPAUL\\\\Downloads\\\\test\\\\marge_simpson\", \n",
    "                \"C:\\\\Users\\\\ASMITPAUL\\\\Downloads\\\\test\\\\milhouse_van_houten\"]\n",
    "\n",
    "image_matrices = read_images_from_folders(folder_paths)\n",
    "\n",
    "image_array = np.array(image_matrices)\n",
    "\n",
    "print(\"Shape of the image array:\", image_array.shape)\n",
    "\n",
    "X_test = image_array.reshape(image_array.shape[0], -1).T/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb58c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test =   [[[1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]]*200 +\n",
    "            [[0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]]*200 +\n",
    "            [[0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]]*200 +\n",
    "            [[0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0]]*200 +\n",
    "            [[0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0]]*200 +\n",
    "            [[0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0]]*200 +\n",
    "            [[0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0]]*200 +\n",
    "            [[0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0]]*200 +\n",
    "            [[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0]]*200 +\n",
    "            [[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0]]*200]\n",
    "        \n",
    "Y_test = np.array(Y_test)\n",
    "Y_test = np.squeeze(Y_test)\n",
    "Y_test.shape\n",
    "Y_test = Y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0b75c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the image array: (10, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "folder_paths = [\"C:\\\\Users\\\\ASMITPAUL\\\\Downloads\\\\test_bonus\"]\n",
    "\n",
    "image_matrices = read_images_from_folders(folder_paths)\n",
    "\n",
    "image_array = np.array(image_matrices)\n",
    "\n",
    "print(\"Shape of the image array:\", image_array.shape)\n",
    "\n",
    "X_test_bonus = image_array.reshape(image_array.shape[0], -1).T/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "832fbb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 6.926576275028\n",
      "Train Accuracy after iteration 0: 10.4375%\n",
      "Test Accuracy after iteration 0: 9.5%\n",
      "Cost after iteration 100: 3.3681930096193655\n",
      "Train Accuracy after iteration 100: 10.125%\n",
      "Test Accuracy after iteration 100: 10.0%\n",
      "Cost after iteration 200: 3.3499927359472492\n",
      "Train Accuracy after iteration 200: 10.675%\n",
      "Test Accuracy after iteration 200: 10.6%\n",
      "Cost after iteration 300: 3.3319345755767134\n",
      "Train Accuracy after iteration 300: 11.8875%\n",
      "Test Accuracy after iteration 300: 11.75%\n",
      "Cost after iteration 400: 3.310950772731207\n",
      "Train Accuracy after iteration 400: 14.5125%\n",
      "Test Accuracy after iteration 400: 15.2%\n",
      "Cost after iteration 500: 3.285229191662192\n",
      "Train Accuracy after iteration 500: 19.7375%\n",
      "Test Accuracy after iteration 500: 19.05%\n",
      "Cost after iteration 600: 3.255513556486716\n",
      "Train Accuracy after iteration 600: 22.1875%\n",
      "Test Accuracy after iteration 600: 21.55%\n",
      "Cost after iteration 700: 3.2256604861144913\n",
      "Train Accuracy after iteration 700: 23.05%\n",
      "Test Accuracy after iteration 700: 22.5%\n",
      "Cost after iteration 800: 3.199852333856317\n",
      "Train Accuracy after iteration 800: 23.525%\n",
      "Test Accuracy after iteration 800: 22.6%\n",
      "Cost after iteration 900: 3.1788947957338314\n",
      "Train Accuracy after iteration 900: 23.725%\n",
      "Test Accuracy after iteration 900: 23.1%\n",
      "Cost after iteration 1000: 3.1612827749172094\n",
      "Train Accuracy after iteration 1000: 23.9375%\n",
      "Test Accuracy after iteration 1000: 23.65%\n",
      "Cost after iteration 1100: 3.1456347122936488\n",
      "Train Accuracy after iteration 1100: 24.3375%\n",
      "Test Accuracy after iteration 1100: 24.1%\n",
      "Cost after iteration 1200: 3.130646716422841\n",
      "Train Accuracy after iteration 1200: 24.8375%\n",
      "Test Accuracy after iteration 1200: 24.25%\n",
      "Cost after iteration 1300: 3.116133269686116\n",
      "Train Accuracy after iteration 1300: 25.225%\n",
      "Test Accuracy after iteration 1300: 25.0%\n",
      "Cost after iteration 1400: 3.1015500219828187\n",
      "Train Accuracy after iteration 1400: 25.925%\n",
      "Test Accuracy after iteration 1400: 25.15%\n",
      "Cost after iteration 1500: 3.0868453235498565\n",
      "Train Accuracy after iteration 1500: 26.375%\n",
      "Test Accuracy after iteration 1500: 25.4%\n",
      "Cost after iteration 1600: 3.072029154286366\n",
      "Train Accuracy after iteration 1600: 26.675%\n",
      "Test Accuracy after iteration 1600: 25.55%\n",
      "Cost after iteration 1700: 3.0574021626477754\n",
      "Train Accuracy after iteration 1700: 27.2625%\n",
      "Test Accuracy after iteration 1700: 25.9%\n",
      "Cost after iteration 1800: 3.042919122542359\n",
      "Train Accuracy after iteration 1800: 27.625%\n",
      "Test Accuracy after iteration 1800: 26.6%\n",
      "Cost after iteration 1900: 3.028667689036016\n",
      "Train Accuracy after iteration 1900: 28.075%\n",
      "Test Accuracy after iteration 1900: 27.1%\n",
      "Cost after iteration 2000: 3.014789714470134\n",
      "Train Accuracy after iteration 2000: 28.5%\n",
      "Test Accuracy after iteration 2000: 27.35%\n",
      "Cost after iteration 2100: 3.0013640773140753\n",
      "Train Accuracy after iteration 2100: 29.0125%\n",
      "Test Accuracy after iteration 2100: 27.85%\n",
      "Cost after iteration 2200: 2.988349891046495\n",
      "Train Accuracy after iteration 2200: 29.55%\n",
      "Test Accuracy after iteration 2200: 27.9%\n",
      "Cost after iteration 2300: 2.975718113602916\n",
      "Train Accuracy after iteration 2300: 29.8%\n",
      "Test Accuracy after iteration 2300: 28.2%\n",
      "Cost after iteration 2400: 2.963457571061382\n",
      "Train Accuracy after iteration 2400: 30.1%\n",
      "Test Accuracy after iteration 2400: 28.6%\n",
      "Cost after iteration 2500: 2.951548613659223\n",
      "Train Accuracy after iteration 2500: 30.5625%\n",
      "Test Accuracy after iteration 2500: 28.65%\n",
      "Cost after iteration 2600: 2.9399687772071257\n",
      "Train Accuracy after iteration 2600: 31.1125%\n",
      "Test Accuracy after iteration 2600: 29.15%\n",
      "Cost after iteration 2700: 2.9286654165614205\n",
      "Train Accuracy after iteration 2700: 31.625%\n",
      "Test Accuracy after iteration 2700: 29.0%\n",
      "Cost after iteration 2800: 2.9175925413107175\n",
      "Train Accuracy after iteration 2800: 31.8875%\n",
      "Test Accuracy after iteration 2800: 29.15%\n",
      "Cost after iteration 2900: 2.906724716730843\n",
      "Train Accuracy after iteration 2900: 32.35%\n",
      "Test Accuracy after iteration 2900: 29.2%\n",
      "Cost after iteration 3000: 2.8960247855758867\n",
      "Train Accuracy after iteration 3000: 32.825%\n",
      "Test Accuracy after iteration 3000: 29.5%\n",
      "Cost after iteration 3100: 2.8854990420956264\n",
      "Train Accuracy after iteration 3100: 33.2125%\n",
      "Test Accuracy after iteration 3100: 29.85%\n",
      "Cost after iteration 3200: 2.875130858820577\n",
      "Train Accuracy after iteration 3200: 33.475%\n",
      "Test Accuracy after iteration 3200: 30.05%\n",
      "Cost after iteration 3300: 2.8649145149246977\n",
      "Train Accuracy after iteration 3300: 33.775%\n",
      "Test Accuracy after iteration 3300: 30.15%\n",
      "Cost after iteration 3400: 2.8548263243627776\n",
      "Train Accuracy after iteration 3400: 34.075%\n",
      "Test Accuracy after iteration 3400: 30.45%\n",
      "Cost after iteration 3500: 2.844851033033299\n",
      "Train Accuracy after iteration 3500: 34.45%\n",
      "Test Accuracy after iteration 3500: 30.75%\n",
      "Cost after iteration 3600: 2.8349823419155467\n",
      "Train Accuracy after iteration 3600: 34.9625%\n",
      "Test Accuracy after iteration 3600: 30.7%\n",
      "Cost after iteration 3700: 2.8252058109456675\n",
      "Train Accuracy after iteration 3700: 35.375%\n",
      "Test Accuracy after iteration 3700: 30.95%\n",
      "Cost after iteration 3800: 2.815489490801023\n",
      "Train Accuracy after iteration 3800: 35.9%\n",
      "Test Accuracy after iteration 3800: 31.2%\n",
      "Cost after iteration 3900: 2.8058094288307998\n",
      "Train Accuracy after iteration 3900: 36.35%\n",
      "Test Accuracy after iteration 3900: 31.3%\n",
      "Cost after iteration 4000: 2.796173874891703\n",
      "Train Accuracy after iteration 4000: 36.6375%\n",
      "Test Accuracy after iteration 4000: 31.65%\n",
      "Cost after iteration 4100: 2.786561409953463\n",
      "Train Accuracy after iteration 4100: 37.1125%\n",
      "Test Accuracy after iteration 4100: 31.75%\n",
      "Cost after iteration 4200: 2.776959378787257\n",
      "Train Accuracy after iteration 4200: 37.425%\n",
      "Test Accuracy after iteration 4200: 31.85%\n",
      "Cost after iteration 4300: 2.7673618754050806\n",
      "Train Accuracy after iteration 4300: 37.8125%\n",
      "Test Accuracy after iteration 4300: 32.15%\n",
      "Cost after iteration 4400: 2.7577424235029575\n",
      "Train Accuracy after iteration 4400: 38.1875%\n",
      "Test Accuracy after iteration 4400: 32.4%\n",
      "Cost after iteration 4500: 2.748111025537418\n",
      "Train Accuracy after iteration 4500: 38.5375%\n",
      "Test Accuracy after iteration 4500: 32.35%\n",
      "Cost after iteration 4600: 2.7384572221484067\n",
      "Train Accuracy after iteration 4600: 38.925%\n",
      "Test Accuracy after iteration 4600: 32.45%\n",
      "Cost after iteration 4700: 2.7287781904322426\n",
      "Train Accuracy after iteration 4700: 39.225%\n",
      "Test Accuracy after iteration 4700: 32.65%\n",
      "Cost after iteration 4800: 2.7190603554304\n",
      "Train Accuracy after iteration 4800: 39.825%\n",
      "Test Accuracy after iteration 4800: 33.1%\n",
      "Cost after iteration 4900: 2.709314828721846\n",
      "Train Accuracy after iteration 4900: 40.0875%\n",
      "Test Accuracy after iteration 4900: 33.15%\n",
      "Cost after iteration 5000: 2.6995338802053643\n",
      "Train Accuracy after iteration 5000: 40.45%\n",
      "Test Accuracy after iteration 5000: 33.15%\n",
      "Cost after iteration 5100: 2.6897099474327297\n",
      "Train Accuracy after iteration 5100: 40.875%\n",
      "Test Accuracy after iteration 5100: 33.25%\n",
      "Cost after iteration 5200: 2.6798565041136726\n",
      "Train Accuracy after iteration 5200: 41.1875%\n",
      "Test Accuracy after iteration 5200: 33.45%\n",
      "Cost after iteration 5300: 2.669956761179215\n",
      "Train Accuracy after iteration 5300: 41.6375%\n",
      "Test Accuracy after iteration 5300: 33.5%\n",
      "Cost after iteration 5400: 2.6600026717279825\n",
      "Train Accuracy after iteration 5400: 41.9875%\n",
      "Test Accuracy after iteration 5400: 33.55%\n",
      "Cost after iteration 5500: 2.650006434920093\n",
      "Train Accuracy after iteration 5500: 42.4375%\n",
      "Test Accuracy after iteration 5500: 33.7%\n",
      "Cost after iteration 5600: 2.6399472561859456\n",
      "Train Accuracy after iteration 5600: 42.6%\n",
      "Test Accuracy after iteration 5600: 33.85%\n",
      "Cost after iteration 5700: 2.6298471805449255\n",
      "Train Accuracy after iteration 5700: 42.8375%\n",
      "Test Accuracy after iteration 5700: 33.9%\n",
      "Cost after iteration 5800: 2.6196963702879548\n",
      "Train Accuracy after iteration 5800: 43.1125%\n",
      "Test Accuracy after iteration 5800: 33.75%\n",
      "Cost after iteration 5900: 2.6095080863345275\n",
      "Train Accuracy after iteration 5900: 43.45%\n",
      "Test Accuracy after iteration 5900: 33.7%\n",
      "Cost after iteration 6000: 2.5993022033637976\n",
      "Train Accuracy after iteration 6000: 43.825%\n",
      "Test Accuracy after iteration 6000: 33.8%\n",
      "Cost after iteration 6100: 2.5891070881134937\n",
      "Train Accuracy after iteration 6100: 44.225%\n",
      "Test Accuracy after iteration 6100: 33.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 6200: 2.578867885829022\n",
      "Train Accuracy after iteration 6200: 44.6375%\n",
      "Test Accuracy after iteration 6200: 33.85%\n",
      "Cost after iteration 6300: 2.56865209874086\n",
      "Train Accuracy after iteration 6300: 44.9625%\n",
      "Test Accuracy after iteration 6300: 33.9%\n",
      "Cost after iteration 6400: 2.5590322757610737\n",
      "Train Accuracy after iteration 6400: 45.225%\n",
      "Test Accuracy after iteration 6400: 33.9%\n",
      "Cost after iteration 6500: 2.54944092815245\n",
      "Train Accuracy after iteration 6500: 45.575%\n",
      "Test Accuracy after iteration 6500: 34.45%\n",
      "Cost after iteration 6600: 2.540037995956064\n",
      "Train Accuracy after iteration 6600: 45.825%\n",
      "Test Accuracy after iteration 6600: 34.5%\n",
      "Cost after iteration 6700: 2.5299883045927607\n",
      "Train Accuracy after iteration 6700: 46.0875%\n",
      "Test Accuracy after iteration 6700: 34.65%\n",
      "Cost after iteration 6800: 2.519794353554791\n",
      "Train Accuracy after iteration 6800: 46.425%\n",
      "Test Accuracy after iteration 6800: 34.7%\n",
      "Cost after iteration 6900: 2.5102678088953168\n",
      "Train Accuracy after iteration 6900: 46.5875%\n",
      "Test Accuracy after iteration 6900: 34.95%\n",
      "Cost after iteration 7000: 2.501187627227488\n",
      "Train Accuracy after iteration 7000: 46.8125%\n",
      "Test Accuracy after iteration 7000: 34.65%\n",
      "Cost after iteration 7100: 2.490515022211613\n",
      "Train Accuracy after iteration 7100: 47.3%\n",
      "Test Accuracy after iteration 7100: 34.85%\n",
      "Cost after iteration 7200: 2.4820082056240915\n",
      "Train Accuracy after iteration 7200: 47.4%\n",
      "Test Accuracy after iteration 7200: 34.95%\n",
      "Cost after iteration 7300: 2.4719135715484364\n",
      "Train Accuracy after iteration 7300: 47.775%\n",
      "Test Accuracy after iteration 7300: 34.9%\n",
      "Cost after iteration 7400: 2.4609858966465548\n",
      "Train Accuracy after iteration 7400: 48.1875%\n",
      "Test Accuracy after iteration 7400: 34.7%\n",
      "Cost after iteration 7500: 2.4525674325421853\n",
      "Train Accuracy after iteration 7500: 48.4875%\n",
      "Test Accuracy after iteration 7500: 34.9%\n",
      "Cost after iteration 7600: 2.4413818126555475\n",
      "Train Accuracy after iteration 7600: 48.8125%\n",
      "Test Accuracy after iteration 7600: 34.75%\n",
      "Cost after iteration 7700: 2.4307501115652297\n",
      "Train Accuracy after iteration 7700: 49.1%\n",
      "Test Accuracy after iteration 7700: 34.8%\n",
      "Cost after iteration 7800: 2.423122240707282\n",
      "Train Accuracy after iteration 7800: 49.375%\n",
      "Test Accuracy after iteration 7800: 35.0%\n",
      "Cost after iteration 7900: 2.410667895180605\n",
      "Train Accuracy after iteration 7900: 49.75%\n",
      "Test Accuracy after iteration 7900: 34.8%\n",
      "Cost after iteration 8000: 2.3998227636936016\n",
      "Train Accuracy after iteration 8000: 50.1375%\n",
      "Test Accuracy after iteration 8000: 34.75%\n",
      "Cost after iteration 8100: 2.3912914903772005\n",
      "Train Accuracy after iteration 8100: 50.2875%\n",
      "Test Accuracy after iteration 8100: 34.95%\n",
      "Cost after iteration 8200: 2.3809421388909384\n",
      "Train Accuracy after iteration 8200: 50.625%\n",
      "Test Accuracy after iteration 8200: 34.95%\n",
      "Cost after iteration 8300: 2.37004850556779\n",
      "Train Accuracy after iteration 8300: 50.8875%\n",
      "Test Accuracy after iteration 8300: 35.1%\n",
      "Cost after iteration 8400: 2.3611371187425894\n",
      "Train Accuracy after iteration 8400: 51.2875%\n",
      "Test Accuracy after iteration 8400: 34.9%\n",
      "Cost after iteration 8500: 2.3512889809404296\n",
      "Train Accuracy after iteration 8500: 51.7125%\n",
      "Test Accuracy after iteration 8500: 34.85%\n",
      "Cost after iteration 8600: 2.3423518594201087\n",
      "Train Accuracy after iteration 8600: 51.625%\n",
      "Test Accuracy after iteration 8600: 35.35%\n",
      "Cost after iteration 8700: 2.3323957988049595\n",
      "Train Accuracy after iteration 8700: 52.3875%\n",
      "Test Accuracy after iteration 8700: 35.2%\n",
      "Cost after iteration 8800: 2.3192971833721496\n",
      "Train Accuracy after iteration 8800: 52.4125%\n",
      "Test Accuracy after iteration 8800: 34.55%\n",
      "Cost after iteration 8900: 2.3161812646352615\n",
      "Train Accuracy after iteration 8900: 52.25%\n",
      "Test Accuracy after iteration 8900: 33.65%\n",
      "Cost after iteration 9000: 2.3095842929117656\n",
      "Train Accuracy after iteration 9000: 52.1%\n",
      "Test Accuracy after iteration 9000: 33.75%\n",
      "Cost after iteration 9100: 2.297924033715911\n",
      "Train Accuracy after iteration 9100: 53.075%\n",
      "Test Accuracy after iteration 9100: 35.35%\n",
      "Cost after iteration 9200: 2.286951901739361\n",
      "Train Accuracy after iteration 9200: 53.0625%\n",
      "Test Accuracy after iteration 9200: 35.25%\n",
      "Cost after iteration 9300: 2.2824495896210277\n",
      "Train Accuracy after iteration 9300: 52.9375%\n",
      "Test Accuracy after iteration 9300: 33.65%\n",
      "Cost after iteration 9400: 2.271650222392435\n",
      "Train Accuracy after iteration 9400: 53.5125%\n",
      "Test Accuracy after iteration 9400: 33.85%\n",
      "Cost after iteration 9500: 2.256071671493801\n",
      "Train Accuracy after iteration 9500: 54.15%\n",
      "Test Accuracy after iteration 9500: 34.05%\n",
      "Cost after iteration 9600: 2.2433378276430607\n",
      "Train Accuracy after iteration 9600: 54.7%\n",
      "Test Accuracy after iteration 9600: 34.4%\n",
      "Cost after iteration 9700: 2.2406192996694525\n",
      "Train Accuracy after iteration 9700: 54.0375%\n",
      "Test Accuracy after iteration 9700: 34.1%\n",
      "Cost after iteration 9800: 2.2333030234561693\n",
      "Train Accuracy after iteration 9800: 54.975%\n",
      "Test Accuracy after iteration 9800: 34.25%\n",
      "Cost after iteration 9900: 2.2261731136819325\n",
      "Train Accuracy after iteration 9900: 54.8125%\n",
      "Test Accuracy after iteration 9900: 33.95%\n",
      "Cost after iteration 10000: 2.213047708882641\n",
      "Train Accuracy after iteration 10000: 55.0125%\n",
      "Test Accuracy after iteration 10000: 34.45%\n",
      "Cost after iteration 10100: 2.2118014902820846\n",
      "Train Accuracy after iteration 10100: 54.65%\n",
      "Test Accuracy after iteration 10100: 35.0%\n",
      "Cost after iteration 10200: 2.1986065571172184\n",
      "Train Accuracy after iteration 10200: 55.8625%\n",
      "Test Accuracy after iteration 10200: 35.3%\n",
      "Cost after iteration 10300: 2.1903153039089074\n",
      "Train Accuracy after iteration 10300: 56.175%\n",
      "Test Accuracy after iteration 10300: 35.7%\n",
      "Cost after iteration 10400: 2.17919687045699\n",
      "Train Accuracy after iteration 10400: 57.0125%\n",
      "Test Accuracy after iteration 10400: 36.45%\n",
      "Cost after iteration 10500: 2.1640560462573366\n",
      "Train Accuracy after iteration 10500: 57.125%\n",
      "Test Accuracy after iteration 10500: 34.85%\n",
      "Cost after iteration 10600: 2.165306977049134\n",
      "Train Accuracy after iteration 10600: 57.2%\n",
      "Test Accuracy after iteration 10600: 36.35%\n",
      "Cost after iteration 10700: 2.150086983780292\n",
      "Train Accuracy after iteration 10700: 56.875%\n",
      "Test Accuracy after iteration 10700: 35.9%\n",
      "Cost after iteration 10800: 2.1472802970585922\n",
      "Train Accuracy after iteration 10800: 57.5875%\n",
      "Test Accuracy after iteration 10800: 35.35%\n",
      "Cost after iteration 10900: 2.127804096778169\n",
      "Train Accuracy after iteration 10900: 58.15%\n",
      "Test Accuracy after iteration 10900: 36.85%\n",
      "Cost after iteration 11000: 2.1131981414603342\n",
      "Train Accuracy after iteration 11000: 58.5%\n",
      "Test Accuracy after iteration 11000: 34.9%\n",
      "Cost after iteration 11100: 2.1137323259059086\n",
      "Train Accuracy after iteration 11100: 57.8625%\n",
      "Test Accuracy after iteration 11100: 35.7%\n",
      "Cost after iteration 11200: 2.1182094926098043\n",
      "Train Accuracy after iteration 11200: 57.425%\n",
      "Test Accuracy after iteration 11200: 34.15%\n",
      "Cost after iteration 11300: 2.0987665826522606\n",
      "Train Accuracy after iteration 11300: 58.625%\n",
      "Test Accuracy after iteration 11300: 36.15%\n",
      "Cost after iteration 11400: 2.0966619823328903\n",
      "Train Accuracy after iteration 11400: 58.15%\n",
      "Test Accuracy after iteration 11400: 35.35%\n",
      "Cost after iteration 11500: 2.0817866632947903\n",
      "Train Accuracy after iteration 11500: 58.75%\n",
      "Test Accuracy after iteration 11500: 34.35%\n",
      "Cost after iteration 11600: 2.0761559133163887\n",
      "Train Accuracy after iteration 11600: 59.2625%\n",
      "Test Accuracy after iteration 11600: 35.55%\n",
      "Cost after iteration 11700: 2.061644590188411\n",
      "Train Accuracy after iteration 11700: 59.425%\n",
      "Test Accuracy after iteration 11700: 35.1%\n",
      "Cost after iteration 11800: 2.0579682732275213\n",
      "Train Accuracy after iteration 11800: 59.8125%\n",
      "Test Accuracy after iteration 11800: 34.95%\n",
      "Cost after iteration 11900: 2.0511217312162264\n",
      "Train Accuracy after iteration 11900: 59.9375%\n",
      "Test Accuracy after iteration 11900: 37.35%\n",
      "Cost after iteration 12000: 2.043828826690667\n",
      "Train Accuracy after iteration 12000: 60.2375%\n",
      "Test Accuracy after iteration 12000: 36.1%\n",
      "Cost after iteration 12100: 2.034167031773424\n",
      "Train Accuracy after iteration 12100: 60.9625%\n",
      "Test Accuracy after iteration 12100: 35.85%\n",
      "Cost after iteration 12200: 2.0295006494235808\n",
      "Train Accuracy after iteration 12200: 60.45%\n",
      "Test Accuracy after iteration 12200: 36.3%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 12300: 2.000946013842152\n",
      "Train Accuracy after iteration 12300: 61.575%\n",
      "Test Accuracy after iteration 12300: 36.0%\n",
      "Cost after iteration 12400: 2.019572559238868\n",
      "Train Accuracy after iteration 12400: 60.2375%\n",
      "Test Accuracy after iteration 12400: 34.25%\n",
      "Cost after iteration 12500: 1.9951345831160612\n",
      "Train Accuracy after iteration 12500: 61.25%\n",
      "Test Accuracy after iteration 12500: 34.45%\n",
      "Cost after iteration 12600: 1.9891113890161218\n",
      "Train Accuracy after iteration 12600: 61.2875%\n",
      "Test Accuracy after iteration 12600: 35.7%\n",
      "Cost after iteration 12700: 1.9838703305932583\n",
      "Train Accuracy after iteration 12700: 62.0125%\n",
      "Test Accuracy after iteration 12700: 36.65%\n",
      "Cost after iteration 12800: 1.9847001076058124\n",
      "Train Accuracy after iteration 12800: 62.0625%\n",
      "Test Accuracy after iteration 12800: 35.85%\n",
      "Cost after iteration 12900: 1.9913257611986372\n",
      "Train Accuracy after iteration 12900: 60.675%\n",
      "Test Accuracy after iteration 12900: 35.7%\n",
      "Cost after iteration 13000: 1.954364526232333\n",
      "Train Accuracy after iteration 13000: 62.95%\n",
      "Test Accuracy after iteration 13000: 36.75%\n",
      "Cost after iteration 13100: 1.9546931328433668\n",
      "Train Accuracy after iteration 13100: 62.675%\n",
      "Test Accuracy after iteration 13100: 35.35%\n",
      "Cost after iteration 13200: 1.9752282911316559\n",
      "Train Accuracy after iteration 13200: 61.5125%\n",
      "Test Accuracy after iteration 13200: 35.7%\n",
      "Cost after iteration 13300: 1.9332089943676096\n",
      "Train Accuracy after iteration 13300: 62.9875%\n",
      "Test Accuracy after iteration 13300: 35.95%\n",
      "Cost after iteration 13400: 1.9265719602718716\n",
      "Train Accuracy after iteration 13400: 63.475%\n",
      "Test Accuracy after iteration 13400: 37.05%\n",
      "Cost after iteration 13500: 1.9042990004374825\n",
      "Train Accuracy after iteration 13500: 64.2875%\n",
      "Test Accuracy after iteration 13500: 35.05%\n",
      "Cost after iteration 13600: 1.9177331894141654\n",
      "Train Accuracy after iteration 13600: 63.7%\n",
      "Test Accuracy after iteration 13600: 35.3%\n",
      "Cost after iteration 13700: 1.885603091620844\n",
      "Train Accuracy after iteration 13700: 64.9%\n",
      "Test Accuracy after iteration 13700: 36.9%\n",
      "Cost after iteration 13800: 1.8781570047119514\n",
      "Train Accuracy after iteration 13800: 64.875%\n",
      "Test Accuracy after iteration 13800: 37.4%\n",
      "Cost after iteration 13900: 1.8759950588907348\n",
      "Train Accuracy after iteration 13900: 65.2125%\n",
      "Test Accuracy after iteration 13900: 37.65%\n",
      "Cost after iteration 14000: 1.8704646998826924\n",
      "Train Accuracy after iteration 14000: 65.1375%\n",
      "Test Accuracy after iteration 14000: 36.4%\n",
      "Cost after iteration 14100: 1.8498127197091498\n",
      "Train Accuracy after iteration 14100: 66.5625%\n",
      "Test Accuracy after iteration 14100: 37.05%\n",
      "Cost after iteration 14200: 1.8679560063992076\n",
      "Train Accuracy after iteration 14200: 65.35%\n",
      "Test Accuracy after iteration 14200: 36.45%\n",
      "Cost after iteration 14300: 1.8893911458285035\n",
      "Train Accuracy after iteration 14300: 64.0%\n",
      "Test Accuracy after iteration 14300: 35.0%\n",
      "Cost after iteration 14400: 1.8429824306964715\n",
      "Train Accuracy after iteration 14400: 66.4125%\n",
      "Test Accuracy after iteration 14400: 37.65%\n",
      "Cost after iteration 14500: 1.8375338774328578\n",
      "Train Accuracy after iteration 14500: 66.2625%\n",
      "Test Accuracy after iteration 14500: 37.05%\n",
      "Cost after iteration 14600: 1.841130163923171\n",
      "Train Accuracy after iteration 14600: 66.1625%\n",
      "Test Accuracy after iteration 14600: 35.8%\n",
      "Cost after iteration 14700: 1.8847671555241077\n",
      "Train Accuracy after iteration 14700: 64.3875%\n",
      "Test Accuracy after iteration 14700: 37.1%\n",
      "Cost after iteration 14800: 1.8360122623019852\n",
      "Train Accuracy after iteration 14800: 65.2375%\n",
      "Test Accuracy after iteration 14800: 37.0%\n",
      "Cost after iteration 14900: 1.8242930129047492\n",
      "Train Accuracy after iteration 14900: 66.1875%\n",
      "Test Accuracy after iteration 14900: 36.6%\n",
      "Cost after iteration 15000: 1.7882087760209748\n",
      "Train Accuracy after iteration 15000: 67.4625%\n",
      "Test Accuracy after iteration 15000: 35.5%\n",
      "Cost after iteration 15100: 1.810309564437768\n",
      "Train Accuracy after iteration 15100: 65.9125%\n",
      "Test Accuracy after iteration 15100: 36.2%\n",
      "Cost after iteration 15200: 1.8209398866908755\n",
      "Train Accuracy after iteration 15200: 65.55%\n",
      "Test Accuracy after iteration 15200: 36.8%\n",
      "Cost after iteration 15300: 1.791517306499536\n",
      "Train Accuracy after iteration 15300: 66.6375%\n",
      "Test Accuracy after iteration 15300: 35.7%\n",
      "Cost after iteration 15400: 1.7545327106462987\n",
      "Train Accuracy after iteration 15400: 69.1375%\n",
      "Test Accuracy after iteration 15400: 38.15%\n",
      "Cost after iteration 15500: 1.783781605931593\n",
      "Train Accuracy after iteration 15500: 67.9%\n",
      "Test Accuracy after iteration 15500: 37.25%\n",
      "Cost after iteration 15600: 1.7589291392967579\n",
      "Train Accuracy after iteration 15600: 68.5375%\n",
      "Test Accuracy after iteration 15600: 38.35%\n",
      "Cost after iteration 15700: 1.713424149839536\n",
      "Train Accuracy after iteration 15700: 69.3375%\n",
      "Test Accuracy after iteration 15700: 37.1%\n",
      "Cost after iteration 15800: 1.7056408644118324\n",
      "Train Accuracy after iteration 15800: 70.2625%\n",
      "Test Accuracy after iteration 15800: 37.5%\n",
      "Cost after iteration 15900: 1.7336827399912358\n",
      "Train Accuracy after iteration 15900: 69.25%\n",
      "Test Accuracy after iteration 15900: 37.45%\n",
      "Cost after iteration 16000: 1.7124451063449715\n",
      "Train Accuracy after iteration 16000: 69.7625%\n",
      "Test Accuracy after iteration 16000: 37.15%\n",
      "Cost after iteration 16100: 1.7051964719054982\n",
      "Train Accuracy after iteration 16100: 69.825%\n",
      "Test Accuracy after iteration 16100: 37.5%\n",
      "Cost after iteration 16200: 1.6881607469309514\n",
      "Train Accuracy after iteration 16200: 70.175%\n",
      "Test Accuracy after iteration 16200: 36.95%\n",
      "Cost after iteration 16300: 1.691484515555951\n",
      "Train Accuracy after iteration 16300: 70.8125%\n",
      "Test Accuracy after iteration 16300: 38.65%\n",
      "Cost after iteration 16400: 1.6743984007783457\n",
      "Train Accuracy after iteration 16400: 71.3875%\n",
      "Test Accuracy after iteration 16400: 38.05%\n",
      "Cost after iteration 16500: 1.6652891622471682\n",
      "Train Accuracy after iteration 16500: 70.625%\n",
      "Test Accuracy after iteration 16500: 38.25%\n",
      "Cost after iteration 16600: 1.658450030289838\n",
      "Train Accuracy after iteration 16600: 71.1375%\n",
      "Test Accuracy after iteration 16600: 37.7%\n",
      "Cost after iteration 16700: 1.6605930875389905\n",
      "Train Accuracy after iteration 16700: 70.9875%\n",
      "Test Accuracy after iteration 16700: 37.3%\n",
      "Cost after iteration 16800: 1.6427956442680933\n",
      "Train Accuracy after iteration 16800: 71.8125%\n",
      "Test Accuracy after iteration 16800: 39.25%\n",
      "Cost after iteration 16900: 1.6061183758586162\n",
      "Train Accuracy after iteration 16900: 72.95%\n",
      "Test Accuracy after iteration 16900: 38.55%\n",
      "Cost after iteration 17000: 1.6486058422777408\n",
      "Train Accuracy after iteration 17000: 70.5125%\n",
      "Test Accuracy after iteration 17000: 39.15%\n",
      "Cost after iteration 17100: 1.6220017555489283\n",
      "Train Accuracy after iteration 17100: 71.8875%\n",
      "Test Accuracy after iteration 17100: 39.15%\n",
      "Cost after iteration 17200: 1.6498393720073392\n",
      "Train Accuracy after iteration 17200: 71.1125%\n",
      "Test Accuracy after iteration 17200: 37.3%\n",
      "Cost after iteration 17300: 1.6436839592328873\n",
      "Train Accuracy after iteration 17300: 71.125%\n",
      "Test Accuracy after iteration 17300: 36.45%\n",
      "Cost after iteration 17400: 1.5865726328614997\n",
      "Train Accuracy after iteration 17400: 72.425%\n",
      "Test Accuracy after iteration 17400: 38.45%\n",
      "Cost after iteration 17500: 1.568416667225886\n",
      "Train Accuracy after iteration 17500: 73.5625%\n",
      "Test Accuracy after iteration 17500: 39.05%\n",
      "Cost after iteration 17600: 1.5931412494701565\n",
      "Train Accuracy after iteration 17600: 72.475%\n",
      "Test Accuracy after iteration 17600: 37.75%\n",
      "Cost after iteration 17700: 1.6095876857197742\n",
      "Train Accuracy after iteration 17700: 72.7125%\n",
      "Test Accuracy after iteration 17700: 38.35%\n",
      "Cost after iteration 17800: 1.5562872486929709\n",
      "Train Accuracy after iteration 17800: 74.0125%\n",
      "Test Accuracy after iteration 17800: 37.4%\n",
      "Cost after iteration 17900: 1.5796187665059906\n",
      "Train Accuracy after iteration 17900: 73.4875%\n",
      "Test Accuracy after iteration 17900: 39.0%\n",
      "Cost after iteration 18000: 1.580324291750416\n",
      "Train Accuracy after iteration 18000: 72.6125%\n",
      "Test Accuracy after iteration 18000: 38.0%\n",
      "Cost after iteration 18100: 1.5736968805312277\n",
      "Train Accuracy after iteration 18100: 72.4625%\n",
      "Test Accuracy after iteration 18100: 37.75%\n",
      "Cost after iteration 18200: 1.4981401685236817\n",
      "Train Accuracy after iteration 18200: 75.5125%\n",
      "Test Accuracy after iteration 18200: 38.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 18300: 1.5232667126537236\n",
      "Train Accuracy after iteration 18300: 74.8375%\n",
      "Test Accuracy after iteration 18300: 39.65%\n",
      "Cost after iteration 18400: 1.4954191135433896\n",
      "Train Accuracy after iteration 18400: 75.25%\n",
      "Test Accuracy after iteration 18400: 38.5%\n",
      "Cost after iteration 18500: 1.5178949611943184\n",
      "Train Accuracy after iteration 18500: 75.9875%\n",
      "Test Accuracy after iteration 18500: 39.15%\n",
      "Cost after iteration 18600: 1.4903216826913348\n",
      "Train Accuracy after iteration 18600: 75.6125%\n",
      "Test Accuracy after iteration 18600: 38.8%\n",
      "Cost after iteration 18700: 1.516060849406414\n",
      "Train Accuracy after iteration 18700: 74.2875%\n",
      "Test Accuracy after iteration 18700: 38.6%\n",
      "Cost after iteration 18800: 1.4775334919283218\n",
      "Train Accuracy after iteration 18800: 75.9625%\n",
      "Test Accuracy after iteration 18800: 38.75%\n",
      "Cost after iteration 18900: 1.5351298335886623\n",
      "Train Accuracy after iteration 18900: 74.5875%\n",
      "Test Accuracy after iteration 18900: 39.7%\n",
      "Cost after iteration 19000: 1.491030613375893\n",
      "Train Accuracy after iteration 19000: 75.375%\n",
      "Test Accuracy after iteration 19000: 37.95%\n",
      "Cost after iteration 19100: 1.4355988986207537\n",
      "Train Accuracy after iteration 19100: 76.5625%\n",
      "Test Accuracy after iteration 19100: 39.25%\n",
      "Cost after iteration 19200: 1.5208389187198241\n",
      "Train Accuracy after iteration 19200: 74.5%\n",
      "Test Accuracy after iteration 19200: 39.9%\n",
      "Cost after iteration 19300: 1.4573307686665133\n",
      "Train Accuracy after iteration 19300: 75.8875%\n",
      "Test Accuracy after iteration 19300: 39.4%\n",
      "Cost after iteration 19400: 1.4198442962637874\n",
      "Train Accuracy after iteration 19400: 77.7875%\n",
      "Test Accuracy after iteration 19400: 39.35%\n",
      "Cost after iteration 19500: 1.400205995194969\n",
      "Train Accuracy after iteration 19500: 78.7125%\n",
      "Test Accuracy after iteration 19500: 39.75%\n",
      "Cost after iteration 19600: 1.4743142924418946\n",
      "Train Accuracy after iteration 19600: 74.7125%\n",
      "Test Accuracy after iteration 19600: 38.25%\n",
      "Cost after iteration 19700: 1.4509840864615322\n",
      "Train Accuracy after iteration 19700: 75.825%\n",
      "Test Accuracy after iteration 19700: 38.6%\n",
      "Cost after iteration 19800: 1.4254306002457864\n",
      "Train Accuracy after iteration 19800: 76.7125%\n",
      "Test Accuracy after iteration 19800: 40.0%\n",
      "Cost after iteration 19900: 1.5363015921254455\n",
      "Train Accuracy after iteration 19900: 73.8%\n",
      "Test Accuracy after iteration 19900: 38.3%\n",
      "Cost after iteration 20000: 1.3577818025252604\n",
      "Train Accuracy after iteration 20000: 79.9%\n",
      "Test Accuracy after iteration 20000: 40.25%\n",
      "Cost after iteration 20100: 1.3838373502202626\n",
      "Train Accuracy after iteration 20100: 77.75%\n",
      "Test Accuracy after iteration 20100: 39.2%\n",
      "Cost after iteration 20200: 1.3784096962566694\n",
      "Train Accuracy after iteration 20200: 78.2%\n",
      "Test Accuracy after iteration 20200: 39.25%\n",
      "Cost after iteration 20300: 1.4337651064598231\n",
      "Train Accuracy after iteration 20300: 77.7625%\n",
      "Test Accuracy after iteration 20300: 39.1%\n",
      "Cost after iteration 20400: 1.4026885238338906\n",
      "Train Accuracy after iteration 20400: 76.675%\n",
      "Test Accuracy after iteration 20400: 38.1%\n",
      "Cost after iteration 20500: 1.3156722505449425\n",
      "Train Accuracy after iteration 20500: 80.05%\n",
      "Test Accuracy after iteration 20500: 40.35%\n",
      "Cost after iteration 20600: 1.3869713689400696\n",
      "Train Accuracy after iteration 20600: 77.975%\n",
      "Test Accuracy after iteration 20600: 38.1%\n",
      "Cost after iteration 20700: 1.3852778358210582\n",
      "Train Accuracy after iteration 20700: 78.15%\n",
      "Test Accuracy after iteration 20700: 38.5%\n",
      "Cost after iteration 20800: 1.2833301950289373\n",
      "Train Accuracy after iteration 20800: 81.875%\n",
      "Test Accuracy after iteration 20800: 39.8%\n",
      "Cost after iteration 20900: 1.3617475598956217\n",
      "Train Accuracy after iteration 20900: 77.75%\n",
      "Test Accuracy after iteration 20900: 39.95%\n",
      "Cost after iteration 21000: 1.3438495846133955\n",
      "Train Accuracy after iteration 21000: 78.3%\n",
      "Test Accuracy after iteration 21000: 39.7%\n",
      "Cost after iteration 21100: 1.322261239121065\n",
      "Train Accuracy after iteration 21100: 79.35%\n",
      "Test Accuracy after iteration 21100: 39.9%\n",
      "Cost after iteration 21200: 1.2838375487464158\n",
      "Train Accuracy after iteration 21200: 80.8125%\n",
      "Test Accuracy after iteration 21200: 40.35%\n",
      "Cost after iteration 21300: 1.2766199583028677\n",
      "Train Accuracy after iteration 21300: 80.625%\n",
      "Test Accuracy after iteration 21300: 40.05%\n",
      "Cost after iteration 21400: 1.3243891263843874\n",
      "Train Accuracy after iteration 21400: 78.8875%\n",
      "Test Accuracy after iteration 21400: 40.45%\n",
      "Cost after iteration 21500: 1.2809282710062735\n",
      "Train Accuracy after iteration 21500: 80.575%\n",
      "Test Accuracy after iteration 21500: 40.85%\n",
      "Cost after iteration 21600: 1.328655134334423\n",
      "Train Accuracy after iteration 21600: 78.9625%\n",
      "Test Accuracy after iteration 21600: 40.35%\n",
      "Cost after iteration 21700: 1.266080206609333\n",
      "Train Accuracy after iteration 21700: 80.2375%\n",
      "Test Accuracy after iteration 21700: 40.1%\n",
      "Cost after iteration 21800: 1.278708952501879\n",
      "Train Accuracy after iteration 21800: 80.9625%\n",
      "Test Accuracy after iteration 21800: 39.45%\n",
      "Cost after iteration 21900: 1.3120462867414207\n",
      "Train Accuracy after iteration 21900: 79.975%\n",
      "Test Accuracy after iteration 21900: 40.25%\n",
      "Cost after iteration 22000: 1.1689192365926016\n",
      "Train Accuracy after iteration 22000: 84.8125%\n",
      "Test Accuracy after iteration 22000: 42.0%\n",
      "Cost after iteration 22100: 1.2853354727888262\n",
      "Train Accuracy after iteration 22100: 80.05%\n",
      "Test Accuracy after iteration 22100: 38.8%\n",
      "Cost after iteration 22200: 1.2682824518387676\n",
      "Train Accuracy after iteration 22200: 80.5375%\n",
      "Test Accuracy after iteration 22200: 39.8%\n",
      "Cost after iteration 22300: 1.2816889693267732\n",
      "Train Accuracy after iteration 22300: 79.4875%\n",
      "Test Accuracy after iteration 22300: 40.4%\n",
      "Cost after iteration 22400: 1.3172802417368366\n",
      "Train Accuracy after iteration 22400: 78.625%\n",
      "Test Accuracy after iteration 22400: 39.45%\n",
      "Cost after iteration 22500: 1.2321004747391089\n",
      "Train Accuracy after iteration 22500: 82.0125%\n",
      "Test Accuracy after iteration 22500: 40.95%\n",
      "Cost after iteration 22600: 1.2525084401171132\n",
      "Train Accuracy after iteration 22600: 80.6625%\n",
      "Test Accuracy after iteration 22600: 40.7%\n",
      "Cost after iteration 22700: 1.127180109457896\n",
      "Train Accuracy after iteration 22700: 85.5625%\n",
      "Test Accuracy after iteration 22700: 41.6%\n",
      "Cost after iteration 22800: 1.191183225002948\n",
      "Train Accuracy after iteration 22800: 83.1%\n",
      "Test Accuracy after iteration 22800: 40.45%\n",
      "Cost after iteration 22900: 1.171256897686346\n",
      "Train Accuracy after iteration 22900: 83.6%\n",
      "Test Accuracy after iteration 22900: 41.05%\n",
      "Cost after iteration 23000: 1.1592991587356958\n",
      "Train Accuracy after iteration 23000: 84.8625%\n",
      "Test Accuracy after iteration 23000: 40.85%\n",
      "Cost after iteration 23100: 1.1331191689846583\n",
      "Train Accuracy after iteration 23100: 84.575%\n",
      "Test Accuracy after iteration 23100: 41.9%\n",
      "Cost after iteration 23200: 1.21641656186864\n",
      "Train Accuracy after iteration 23200: 81.8375%\n",
      "Test Accuracy after iteration 23200: 40.45%\n",
      "Cost after iteration 23300: 1.1961200541812853\n",
      "Train Accuracy after iteration 23300: 82.95%\n",
      "Test Accuracy after iteration 23300: 41.25%\n",
      "Cost after iteration 23400: 1.1822371415329715\n",
      "Train Accuracy after iteration 23400: 82.3375%\n",
      "Test Accuracy after iteration 23400: 40.6%\n",
      "Cost after iteration 23500: 1.1663919987401568\n",
      "Train Accuracy after iteration 23500: 82.2375%\n",
      "Test Accuracy after iteration 23500: 41.0%\n",
      "Cost after iteration 23600: 1.1360395480549086\n",
      "Train Accuracy after iteration 23600: 84.0375%\n",
      "Test Accuracy after iteration 23600: 40.75%\n",
      "Cost after iteration 23700: 1.1726874373809544\n",
      "Train Accuracy after iteration 23700: 83.925%\n",
      "Test Accuracy after iteration 23700: 40.0%\n",
      "Cost after iteration 23800: 1.0999280120500465\n",
      "Train Accuracy after iteration 23800: 85.95%\n",
      "Test Accuracy after iteration 23800: 41.05%\n",
      "Cost after iteration 23900: 1.1646509975451989\n",
      "Train Accuracy after iteration 23900: 83.175%\n",
      "Test Accuracy after iteration 23900: 40.6%\n",
      "Cost after iteration 24000: 1.1419799567051327\n",
      "Train Accuracy after iteration 24000: 84.9%\n",
      "Test Accuracy after iteration 24000: 41.8%\n",
      "Cost after iteration 24100: 1.0656906972256157\n",
      "Train Accuracy after iteration 24100: 86.4125%\n",
      "Test Accuracy after iteration 24100: 41.3%\n",
      "Cost after iteration 24200: 1.0449316733344323\n",
      "Train Accuracy after iteration 24200: 86.8875%\n",
      "Test Accuracy after iteration 24200: 41.5%\n",
      "Cost after iteration 24300: 1.0594721994029481\n",
      "Train Accuracy after iteration 24300: 86.6875%\n",
      "Test Accuracy after iteration 24300: 42.9%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 24400: 1.0541516469909218\n",
      "Train Accuracy after iteration 24400: 86.6375%\n",
      "Test Accuracy after iteration 24400: 42.25%\n",
      "Cost after iteration 24500: 1.0844435303386728\n",
      "Train Accuracy after iteration 24500: 86.125%\n",
      "Test Accuracy after iteration 24500: 40.75%\n",
      "Cost after iteration 24600: 1.033390054551259\n",
      "Train Accuracy after iteration 24600: 87.1125%\n",
      "Test Accuracy after iteration 24600: 42.1%\n",
      "Cost after iteration 24700: 1.1463995972228185\n",
      "Train Accuracy after iteration 24700: 82.525%\n",
      "Test Accuracy after iteration 24700: 40.65%\n",
      "Cost after iteration 24800: 1.057389468016071\n",
      "Train Accuracy after iteration 24800: 86.6625%\n",
      "Test Accuracy after iteration 24800: 41.35%\n",
      "Cost after iteration 24900: 1.0501513879414757\n",
      "Train Accuracy after iteration 24900: 86.9375%\n",
      "Test Accuracy after iteration 24900: 41.35%\n",
      "Cost after iteration 25000: 1.0446941220568613\n",
      "Train Accuracy after iteration 25000: 86.4875%\n",
      "Test Accuracy after iteration 25000: 41.45%\n",
      "Cost after iteration 25100: 1.0766003848147283\n",
      "Train Accuracy after iteration 25100: 84.9125%\n",
      "Test Accuracy after iteration 25100: 41.25%\n",
      "Cost after iteration 25200: 1.0786710429002546\n",
      "Train Accuracy after iteration 25200: 85.7875%\n",
      "Test Accuracy after iteration 25200: 41.6%\n",
      "Cost after iteration 25300: 1.0274077586825598\n",
      "Train Accuracy after iteration 25300: 87.025%\n",
      "Test Accuracy after iteration 25300: 41.45%\n",
      "Cost after iteration 25400: 1.027025483784414\n",
      "Train Accuracy after iteration 25400: 86.775%\n",
      "Test Accuracy after iteration 25400: 41.15%\n",
      "Cost after iteration 25500: 0.9743805852865774\n",
      "Train Accuracy after iteration 25500: 88.0625%\n",
      "Test Accuracy after iteration 25500: 41.7%\n",
      "Cost after iteration 25600: 0.9954172237087673\n",
      "Train Accuracy after iteration 25600: 87.7625%\n",
      "Test Accuracy after iteration 25600: 42.5%\n",
      "Cost after iteration 25700: 1.006258740365674\n",
      "Train Accuracy after iteration 25700: 88.0125%\n",
      "Test Accuracy after iteration 25700: 41.05%\n",
      "Cost after iteration 25800: 0.9406770636635863\n",
      "Train Accuracy after iteration 25800: 89.35%\n",
      "Test Accuracy after iteration 25800: 42.8%\n",
      "Cost after iteration 25900: 0.9491924277629363\n",
      "Train Accuracy after iteration 25900: 88.7625%\n",
      "Test Accuracy after iteration 25900: 41.25%\n",
      "Cost after iteration 26000: 0.9165967096389106\n",
      "Train Accuracy after iteration 26000: 90.075%\n",
      "Test Accuracy after iteration 26000: 42.5%\n",
      "Cost after iteration 26100: 0.9712530991832788\n",
      "Train Accuracy after iteration 26100: 88.6625%\n",
      "Test Accuracy after iteration 26100: 41.7%\n",
      "Cost after iteration 26200: 0.9285865193227104\n",
      "Train Accuracy after iteration 26200: 89.3%\n",
      "Test Accuracy after iteration 26200: 41.95%\n",
      "Cost after iteration 26300: 0.9604938326967156\n",
      "Train Accuracy after iteration 26300: 87.875%\n",
      "Test Accuracy after iteration 26300: 42.1%\n",
      "Cost after iteration 26400: 0.9801526819600271\n",
      "Train Accuracy after iteration 26400: 87.175%\n",
      "Test Accuracy after iteration 26400: 41.65%\n",
      "Cost after iteration 26500: 0.9296746632751411\n",
      "Train Accuracy after iteration 26500: 88.7375%\n",
      "Test Accuracy after iteration 26500: 41.7%\n",
      "Cost after iteration 26600: 0.9378874233149507\n",
      "Train Accuracy after iteration 26600: 89.3375%\n",
      "Test Accuracy after iteration 26600: 41.85%\n",
      "Cost after iteration 26700: 0.9258854044176232\n",
      "Train Accuracy after iteration 26700: 89.6625%\n",
      "Test Accuracy after iteration 26700: 41.65%\n",
      "Cost after iteration 26800: 0.934731681247128\n",
      "Train Accuracy after iteration 26800: 88.45%\n",
      "Test Accuracy after iteration 26800: 41.2%\n",
      "Cost after iteration 26900: 0.9049270037464232\n",
      "Train Accuracy after iteration 26900: 90.3625%\n",
      "Test Accuracy after iteration 26900: 42.45%\n",
      "Cost after iteration 27000: 0.9099996243470446\n",
      "Train Accuracy after iteration 27000: 89.5875%\n",
      "Test Accuracy after iteration 27000: 42.35%\n",
      "Cost after iteration 27100: 0.8751509933048465\n",
      "Train Accuracy after iteration 27100: 90.175%\n",
      "Test Accuracy after iteration 27100: 42.6%\n",
      "Cost after iteration 27200: 0.8751362113870762\n",
      "Train Accuracy after iteration 27200: 89.5125%\n",
      "Test Accuracy after iteration 27200: 42.75%\n",
      "Cost after iteration 27300: 0.8671772460857237\n",
      "Train Accuracy after iteration 27300: 91.575%\n",
      "Test Accuracy after iteration 27300: 42.9%\n",
      "Cost after iteration 27400: 0.8827131223507604\n",
      "Train Accuracy after iteration 27400: 89.6375%\n",
      "Test Accuracy after iteration 27400: 42.05%\n",
      "Cost after iteration 27500: 0.9088844528143889\n",
      "Train Accuracy after iteration 27500: 89.725%\n",
      "Test Accuracy after iteration 27500: 42.15%\n",
      "Cost after iteration 27600: 0.8546380302967469\n",
      "Train Accuracy after iteration 27600: 90.4125%\n",
      "Test Accuracy after iteration 27600: 42.6%\n",
      "Cost after iteration 27700: 0.9004628592452245\n",
      "Train Accuracy after iteration 27700: 89.1875%\n",
      "Test Accuracy after iteration 27700: 41.55%\n",
      "Cost after iteration 27800: 0.8351749606252197\n",
      "Train Accuracy after iteration 27800: 91.55%\n",
      "Test Accuracy after iteration 27800: 42.35%\n",
      "Cost after iteration 27900: 0.8618340389498467\n",
      "Train Accuracy after iteration 27900: 90.5625%\n",
      "Test Accuracy after iteration 27900: 41.75%\n",
      "Cost after iteration 28000: 0.8066881866739287\n",
      "Train Accuracy after iteration 28000: 91.7875%\n",
      "Test Accuracy after iteration 28000: 42.9%\n",
      "Cost after iteration 28100: 0.8591026323261451\n",
      "Train Accuracy after iteration 28100: 90.45%\n",
      "Test Accuracy after iteration 28100: 43.35%\n",
      "Cost after iteration 28200: 0.80798416027751\n",
      "Train Accuracy after iteration 28200: 91.5%\n",
      "Test Accuracy after iteration 28200: 42.6%\n",
      "Cost after iteration 28300: 0.8387469284498393\n",
      "Train Accuracy after iteration 28300: 91.0625%\n",
      "Test Accuracy after iteration 28300: 43.05%\n",
      "Cost after iteration 28400: 0.7652392113987885\n",
      "Train Accuracy after iteration 28400: 93.1625%\n",
      "Test Accuracy after iteration 28400: 42.65%\n",
      "Cost after iteration 28500: 0.7597643508767538\n",
      "Train Accuracy after iteration 28500: 93.0875%\n",
      "Test Accuracy after iteration 28500: 43.35%\n",
      "Cost after iteration 28600: 0.7981147839260657\n",
      "Train Accuracy after iteration 28600: 92.6875%\n",
      "Test Accuracy after iteration 28600: 42.45%\n",
      "Cost after iteration 28700: 0.8528167242796058\n",
      "Train Accuracy after iteration 28700: 90.6625%\n",
      "Test Accuracy after iteration 28700: 42.45%\n",
      "Cost after iteration 28800: 0.7532543342716739\n",
      "Train Accuracy after iteration 28800: 93.175%\n",
      "Test Accuracy after iteration 28800: 43.3%\n",
      "Cost after iteration 28900: 0.7932659274012347\n",
      "Train Accuracy after iteration 28900: 92.925%\n",
      "Test Accuracy after iteration 28900: 42.25%\n",
      "Cost after iteration 29000: 0.8623872607029647\n",
      "Train Accuracy after iteration 29000: 89.5125%\n",
      "Test Accuracy after iteration 29000: 42.25%\n",
      "Cost after iteration 29100: 0.7376773118162099\n",
      "Train Accuracy after iteration 29100: 93.375%\n",
      "Test Accuracy after iteration 29100: 44.1%\n",
      "Cost after iteration 29200: 0.7689287047197356\n",
      "Train Accuracy after iteration 29200: 92.15%\n",
      "Test Accuracy after iteration 29200: 42.65%\n",
      "Cost after iteration 29300: 0.7228314049444949\n",
      "Train Accuracy after iteration 29300: 93.125%\n",
      "Test Accuracy after iteration 29300: 43.65%\n",
      "Cost after iteration 29400: 0.7076246827122401\n",
      "Train Accuracy after iteration 29400: 94.15%\n",
      "Test Accuracy after iteration 29400: 44.55%\n",
      "Cost after iteration 29500: 0.753365272401773\n",
      "Train Accuracy after iteration 29500: 92.3375%\n",
      "Test Accuracy after iteration 29500: 43.15%\n",
      "Cost after iteration 29600: 0.7147886426400241\n",
      "Train Accuracy after iteration 29600: 93.15%\n",
      "Test Accuracy after iteration 29600: 43.2%\n",
      "Cost after iteration 29700: 0.7453797927958272\n",
      "Train Accuracy after iteration 29700: 92.675%\n",
      "Test Accuracy after iteration 29700: 43.0%\n",
      "Cost after iteration 29800: 0.7760118341835426\n",
      "Train Accuracy after iteration 29800: 91.8375%\n",
      "Test Accuracy after iteration 29800: 43.05%\n",
      "Cost after iteration 29900: 0.7614155145172122\n",
      "Train Accuracy after iteration 29900: 92.6%\n",
      "Test Accuracy after iteration 29900: 42.8%\n",
      "Cost after iteration 30000: 0.6935435761321299\n",
      "Train Accuracy after iteration 30000: 94.25%\n",
      "Test Accuracy after iteration 30000: 43.3%\n",
      "Cost after iteration 30100: 0.7129449834170517\n",
      "Train Accuracy after iteration 30100: 93.3625%\n",
      "Test Accuracy after iteration 30100: 43.2%\n",
      "Cost after iteration 30200: 0.7102412951447912\n",
      "Train Accuracy after iteration 30200: 93.425%\n",
      "Test Accuracy after iteration 30200: 43.6%\n",
      "Cost after iteration 30300: 0.674649300230558\n",
      "Train Accuracy after iteration 30300: 95.2625%\n",
      "Test Accuracy after iteration 30300: 44.2%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 30400: 0.6885632657406424\n",
      "Train Accuracy after iteration 30400: 94.575%\n",
      "Test Accuracy after iteration 30400: 43.85%\n",
      "Cost after iteration 30500: 0.6633656854772219\n",
      "Train Accuracy after iteration 30500: 94.6875%\n",
      "Test Accuracy after iteration 30500: 43.8%\n",
      "Cost after iteration 30600: 0.684325229962852\n",
      "Train Accuracy after iteration 30600: 94.2%\n",
      "Test Accuracy after iteration 30600: 43.65%\n",
      "Cost after iteration 30700: 0.6694623729347637\n",
      "Train Accuracy after iteration 30700: 94.725%\n",
      "Test Accuracy after iteration 30700: 43.65%\n",
      "Cost after iteration 30800: 0.6806384426192872\n",
      "Train Accuracy after iteration 30800: 94.1%\n",
      "Test Accuracy after iteration 30800: 43.3%\n",
      "Cost after iteration 30900: 0.6641169619648223\n",
      "Train Accuracy after iteration 30900: 94.2125%\n",
      "Test Accuracy after iteration 30900: 42.75%\n",
      "Cost after iteration 31000: 0.6632520844600054\n",
      "Train Accuracy after iteration 31000: 95.075%\n",
      "Test Accuracy after iteration 31000: 43.15%\n",
      "Cost after iteration 31100: 0.7074657455919866\n",
      "Train Accuracy after iteration 31100: 93.625%\n",
      "Test Accuracy after iteration 31100: 42.15%\n",
      "Cost after iteration 31200: 0.6242252535208863\n",
      "Train Accuracy after iteration 31200: 95.375%\n",
      "Test Accuracy after iteration 31200: 43.5%\n",
      "Cost after iteration 31300: 0.6050640532247697\n",
      "Train Accuracy after iteration 31300: 96.075%\n",
      "Test Accuracy after iteration 31300: 44.55%\n",
      "Cost after iteration 31400: 0.6246835949996609\n",
      "Train Accuracy after iteration 31400: 94.6875%\n",
      "Test Accuracy after iteration 31400: 43.6%\n",
      "Cost after iteration 31500: 0.7006303348754809\n",
      "Train Accuracy after iteration 31500: 93.675%\n",
      "Test Accuracy after iteration 31500: 42.65%\n",
      "Cost after iteration 31600: 0.6093091507736652\n",
      "Train Accuracy after iteration 31600: 95.2375%\n",
      "Test Accuracy after iteration 31600: 43.35%\n",
      "Cost after iteration 31700: 0.7698047293654798\n",
      "Train Accuracy after iteration 31700: 92.525%\n",
      "Test Accuracy after iteration 31700: 42.6%\n",
      "Cost after iteration 31800: 0.6810371104089991\n",
      "Train Accuracy after iteration 31800: 93.6%\n",
      "Test Accuracy after iteration 31800: 42.85%\n",
      "Cost after iteration 31900: 0.6486486969113838\n",
      "Train Accuracy after iteration 31900: 94.1625%\n",
      "Test Accuracy after iteration 31900: 43.8%\n",
      "Cost after iteration 32000: 0.7715263917306848\n",
      "Train Accuracy after iteration 32000: 92.3625%\n",
      "Test Accuracy after iteration 32000: 42.65%\n",
      "Cost after iteration 32100: 0.5699558989249945\n",
      "Train Accuracy after iteration 32100: 96.35%\n",
      "Test Accuracy after iteration 32100: 43.95%\n",
      "Cost after iteration 32200: 0.5936187670331251\n",
      "Train Accuracy after iteration 32200: 95.8375%\n",
      "Test Accuracy after iteration 32200: 43.8%\n",
      "Cost after iteration 32300: 0.6123920830482883\n",
      "Train Accuracy after iteration 32300: 95.7625%\n",
      "Test Accuracy after iteration 32300: 42.95%\n",
      "Cost after iteration 32400: 0.5919767759046783\n",
      "Train Accuracy after iteration 32400: 95.775%\n",
      "Test Accuracy after iteration 32400: 43.6%\n",
      "Cost after iteration 32500: 0.5421737110707465\n",
      "Train Accuracy after iteration 32500: 96.85%\n",
      "Test Accuracy after iteration 32500: 43.8%\n",
      "Cost after iteration 32600: 0.5783598433743026\n",
      "Train Accuracy after iteration 32600: 96.025%\n",
      "Test Accuracy after iteration 32600: 43.45%\n",
      "Cost after iteration 32700: 0.5627977200991768\n",
      "Train Accuracy after iteration 32700: 96.375%\n",
      "Test Accuracy after iteration 32700: 43.4%\n",
      "Cost after iteration 32800: 0.5871188476789032\n",
      "Train Accuracy after iteration 32800: 95.2625%\n",
      "Test Accuracy after iteration 32800: 44.15%\n",
      "Cost after iteration 32900: 0.5579727408566593\n",
      "Train Accuracy after iteration 32900: 95.9%\n",
      "Test Accuracy after iteration 32900: 44.05%\n",
      "Cost after iteration 33000: 0.660987656208233\n",
      "Train Accuracy after iteration 33000: 93.95%\n",
      "Test Accuracy after iteration 33000: 43.4%\n",
      "Cost after iteration 33100: 0.665491265250234\n",
      "Train Accuracy after iteration 33100: 93.775%\n",
      "Test Accuracy after iteration 33100: 42.95%\n",
      "Cost after iteration 33200: 0.5081977785469897\n",
      "Train Accuracy after iteration 33200: 97.05%\n",
      "Test Accuracy after iteration 33200: 43.6%\n",
      "Cost after iteration 33300: 0.5407582999452009\n",
      "Train Accuracy after iteration 33300: 96.25%\n",
      "Test Accuracy after iteration 33300: 44.75%\n",
      "Cost after iteration 33400: 0.6219341906890761\n",
      "Train Accuracy after iteration 33400: 94.425%\n",
      "Test Accuracy after iteration 33400: 43.2%\n",
      "Cost after iteration 33500: 0.5374626416735311\n",
      "Train Accuracy after iteration 33500: 96.3625%\n",
      "Test Accuracy after iteration 33500: 44.25%\n",
      "Cost after iteration 33600: 0.5025727498793634\n",
      "Train Accuracy after iteration 33600: 97.1125%\n",
      "Test Accuracy after iteration 33600: 43.9%\n",
      "Cost after iteration 33700: 0.5092210923596\n",
      "Train Accuracy after iteration 33700: 96.6875%\n",
      "Test Accuracy after iteration 33700: 44.2%\n",
      "Cost after iteration 33800: 0.5370544568409786\n",
      "Train Accuracy after iteration 33800: 96.325%\n",
      "Test Accuracy after iteration 33800: 43.7%\n",
      "Cost after iteration 33900: 0.5148604998484129\n",
      "Train Accuracy after iteration 33900: 96.8125%\n",
      "Test Accuracy after iteration 33900: 44.15%\n",
      "Cost after iteration 34000: 0.4826639236991376\n",
      "Train Accuracy after iteration 34000: 97.475%\n",
      "Test Accuracy after iteration 34000: 43.75%\n",
      "Cost after iteration 34100: 0.5611953602281746\n",
      "Train Accuracy after iteration 34100: 95.0375%\n",
      "Test Accuracy after iteration 34100: 43.35%\n",
      "Cost after iteration 34200: 0.5330667430875903\n",
      "Train Accuracy after iteration 34200: 96.15%\n",
      "Test Accuracy after iteration 34200: 43.7%\n",
      "Cost after iteration 34300: 0.4891124074076031\n",
      "Train Accuracy after iteration 34300: 97.25%\n",
      "Test Accuracy after iteration 34300: 43.95%\n",
      "Cost after iteration 34400: 0.5083949831988801\n",
      "Train Accuracy after iteration 34400: 96.6125%\n",
      "Test Accuracy after iteration 34400: 43.95%\n",
      "Cost after iteration 34500: 0.5374333231860934\n",
      "Train Accuracy after iteration 34500: 95.8%\n",
      "Test Accuracy after iteration 34500: 44.1%\n",
      "Cost after iteration 34600: 0.5130635156167236\n",
      "Train Accuracy after iteration 34600: 95.9625%\n",
      "Test Accuracy after iteration 34600: 43.9%\n",
      "Cost after iteration 34700: 0.4788969263611163\n",
      "Train Accuracy after iteration 34700: 97.5875%\n",
      "Test Accuracy after iteration 34700: 44.1%\n",
      "Cost after iteration 34800: 0.6114472918697941\n",
      "Train Accuracy after iteration 34800: 94.925%\n",
      "Test Accuracy after iteration 34800: 44.1%\n",
      "Cost after iteration 34900: 0.519900501743611\n",
      "Train Accuracy after iteration 34900: 96.65%\n",
      "Test Accuracy after iteration 34900: 44.8%\n",
      "Cost after iteration 35000: 0.4403361760430998\n",
      "Train Accuracy after iteration 35000: 97.8875%\n",
      "Test Accuracy after iteration 35000: 43.9%\n",
      "Cost after iteration 35100: 0.4369714421705597\n",
      "Train Accuracy after iteration 35100: 98.075%\n",
      "Test Accuracy after iteration 35100: 44.0%\n",
      "Cost after iteration 35200: 0.4412926840506075\n",
      "Train Accuracy after iteration 35200: 97.775%\n",
      "Test Accuracy after iteration 35200: 45.15%\n",
      "Cost after iteration 35300: 0.49170160373071864\n",
      "Train Accuracy after iteration 35300: 96.55%\n",
      "Test Accuracy after iteration 35300: 44.25%\n",
      "Cost after iteration 35400: 0.44645656548431223\n",
      "Train Accuracy after iteration 35400: 97.2125%\n",
      "Test Accuracy after iteration 35400: 44.4%\n",
      "Cost after iteration 35500: 0.44240251088208093\n",
      "Train Accuracy after iteration 35500: 98.0625%\n",
      "Test Accuracy after iteration 35500: 44.45%\n",
      "Cost after iteration 35600: 0.4448616842713627\n",
      "Train Accuracy after iteration 35600: 97.8125%\n",
      "Test Accuracy after iteration 35600: 43.5%\n",
      "Cost after iteration 35700: 0.4304187036333892\n",
      "Train Accuracy after iteration 35700: 98.1375%\n",
      "Test Accuracy after iteration 35700: 44.1%\n",
      "Cost after iteration 35800: 0.42020860751802364\n",
      "Train Accuracy after iteration 35800: 98.2375%\n",
      "Test Accuracy after iteration 35800: 44.0%\n",
      "Cost after iteration 35900: 0.39996901272095986\n",
      "Train Accuracy after iteration 35900: 98.6%\n",
      "Test Accuracy after iteration 35900: 44.9%\n",
      "Cost after iteration 36000: 0.45898036155060856\n",
      "Train Accuracy after iteration 36000: 96.975%\n",
      "Test Accuracy after iteration 36000: 44.35%\n",
      "Cost after iteration 36100: 0.4224908406732785\n",
      "Train Accuracy after iteration 36100: 97.75%\n",
      "Test Accuracy after iteration 36100: 44.45%\n",
      "Cost after iteration 36200: 0.44502419222274253\n",
      "Train Accuracy after iteration 36200: 97.3375%\n",
      "Test Accuracy after iteration 36200: 44.0%\n",
      "Cost after iteration 36300: 0.4205111161699161\n",
      "Train Accuracy after iteration 36300: 97.8625%\n",
      "Test Accuracy after iteration 36300: 44.8%\n",
      "Cost after iteration 36400: 0.5167601652502257\n",
      "Train Accuracy after iteration 36400: 95.4375%\n",
      "Test Accuracy after iteration 36400: 44.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 36500: 0.4316401501009363\n",
      "Train Accuracy after iteration 36500: 97.2875%\n",
      "Test Accuracy after iteration 36500: 44.65%\n",
      "Cost after iteration 36600: 0.4206168857129754\n",
      "Train Accuracy after iteration 36600: 97.7125%\n",
      "Test Accuracy after iteration 36600: 45.1%\n",
      "Cost after iteration 36700: 0.3958773718974123\n",
      "Train Accuracy after iteration 36700: 98.4125%\n",
      "Test Accuracy after iteration 36700: 44.1%\n",
      "Cost after iteration 36800: 0.3963218258239566\n",
      "Train Accuracy after iteration 36800: 98.15%\n",
      "Test Accuracy after iteration 36800: 44.05%\n",
      "Cost after iteration 36900: 0.39679282678372413\n",
      "Train Accuracy after iteration 36900: 98.075%\n",
      "Test Accuracy after iteration 36900: 44.0%\n",
      "Cost after iteration 37000: 0.35416185646868503\n",
      "Train Accuracy after iteration 37000: 98.8625%\n",
      "Test Accuracy after iteration 37000: 44.85%\n",
      "Cost after iteration 37100: 0.5501204215807551\n",
      "Train Accuracy after iteration 37100: 94.4625%\n",
      "Test Accuracy after iteration 37100: 44.05%\n",
      "Cost after iteration 37200: 0.3405085746360818\n",
      "Train Accuracy after iteration 37200: 99.0625%\n",
      "Test Accuracy after iteration 37200: 45.4%\n",
      "Cost after iteration 37300: 0.39427236870599774\n",
      "Train Accuracy after iteration 37300: 98.3625%\n",
      "Test Accuracy after iteration 37300: 44.1%\n",
      "Cost after iteration 37400: 0.327226512246443\n",
      "Train Accuracy after iteration 37400: 99.2%\n",
      "Test Accuracy after iteration 37400: 45.4%\n",
      "Cost after iteration 37500: 0.37514949032268763\n",
      "Train Accuracy after iteration 37500: 98.95%\n",
      "Test Accuracy after iteration 37500: 44.4%\n",
      "Cost after iteration 37600: 0.3952825644455703\n",
      "Train Accuracy after iteration 37600: 98.075%\n",
      "Test Accuracy after iteration 37600: 44.45%\n",
      "Cost after iteration 37700: 0.46720410760572106\n",
      "Train Accuracy after iteration 37700: 96.25%\n",
      "Test Accuracy after iteration 37700: 44.0%\n",
      "Cost after iteration 37800: 0.3526025759308791\n",
      "Train Accuracy after iteration 37800: 98.8%\n",
      "Test Accuracy after iteration 37800: 45.2%\n",
      "Cost after iteration 37900: 0.3272798100418362\n",
      "Train Accuracy after iteration 37900: 99.2125%\n",
      "Test Accuracy after iteration 37900: 44.65%\n",
      "Cost after iteration 38000: 0.31481595166258863\n",
      "Train Accuracy after iteration 38000: 99.35%\n",
      "Test Accuracy after iteration 38000: 45.25%\n",
      "Cost after iteration 38100: 0.3038577219404367\n",
      "Train Accuracy after iteration 38100: 99.375%\n",
      "Test Accuracy after iteration 38100: 45.15%\n",
      "Cost after iteration 38200: 0.4554497165025625\n",
      "Train Accuracy after iteration 38200: 96.725%\n",
      "Test Accuracy after iteration 38200: 44.3%\n",
      "Cost after iteration 38300: 0.3277379907788419\n",
      "Train Accuracy after iteration 38300: 99.1125%\n",
      "Test Accuracy after iteration 38300: 45.1%\n",
      "Cost after iteration 38400: 0.3030700669322096\n",
      "Train Accuracy after iteration 38400: 99.4375%\n",
      "Test Accuracy after iteration 38400: 45.25%\n",
      "Cost after iteration 38500: 0.3778276757683943\n",
      "Train Accuracy after iteration 38500: 98.2875%\n",
      "Test Accuracy after iteration 38500: 44.85%\n",
      "Cost after iteration 38600: 0.29294839254664523\n",
      "Train Accuracy after iteration 38600: 99.4375%\n",
      "Test Accuracy after iteration 38600: 45.3%\n",
      "Cost after iteration 38700: 0.40349746401677583\n",
      "Train Accuracy after iteration 38700: 97.4%\n",
      "Test Accuracy after iteration 38700: 44.25%\n",
      "Cost after iteration 38800: 0.3613321645610059\n",
      "Train Accuracy after iteration 38800: 98.5875%\n",
      "Test Accuracy after iteration 38800: 44.95%\n",
      "Cost after iteration 38900: 0.28859248341751986\n",
      "Train Accuracy after iteration 38900: 99.3875%\n",
      "Test Accuracy after iteration 38900: 45.6%\n",
      "Cost after iteration 39000: 0.28266449104229413\n",
      "Train Accuracy after iteration 39000: 99.5%\n",
      "Test Accuracy after iteration 39000: 45.6%\n",
      "Cost after iteration 39100: 0.2917456871417548\n",
      "Train Accuracy after iteration 39100: 99.4375%\n",
      "Test Accuracy after iteration 39100: 45.2%\n",
      "Cost after iteration 39200: 0.2812622161457308\n",
      "Train Accuracy after iteration 39200: 99.5125%\n",
      "Test Accuracy after iteration 39200: 45.35%\n",
      "Cost after iteration 39300: 0.37346210193495344\n",
      "Train Accuracy after iteration 39300: 97.8125%\n",
      "Test Accuracy after iteration 39300: 44.95%\n",
      "Cost after iteration 39400: 0.2772107010386688\n",
      "Train Accuracy after iteration 39400: 99.5875%\n",
      "Test Accuracy after iteration 39400: 45.65%\n",
      "Cost after iteration 39500: 0.30917158092598873\n",
      "Train Accuracy after iteration 39500: 99.2125%\n",
      "Test Accuracy after iteration 39500: 45.05%\n",
      "Cost after iteration 39600: 0.37577776001974644\n",
      "Train Accuracy after iteration 39600: 98.625%\n",
      "Test Accuracy after iteration 39600: 44.1%\n",
      "Cost after iteration 39700: 0.2670772185614779\n",
      "Train Accuracy after iteration 39700: 99.5875%\n",
      "Test Accuracy after iteration 39700: 45.7%\n",
      "Cost after iteration 39800: 0.2809126252615882\n",
      "Train Accuracy after iteration 39800: 99.4875%\n",
      "Test Accuracy after iteration 39800: 45.7%\n",
      "Cost after iteration 39900: 0.31005437947494113\n",
      "Train Accuracy after iteration 39900: 99.3%\n",
      "Test Accuracy after iteration 39900: 44.85%\n",
      "Cost after iteration 40000: 0.2613620618711422\n",
      "Train Accuracy after iteration 40000: 99.6125%\n",
      "Test Accuracy after iteration 40000: 45.45%\n",
      "Cost after iteration 40100: 0.2590170854618391\n",
      "Train Accuracy after iteration 40100: 99.6375%\n",
      "Test Accuracy after iteration 40100: 45.45%\n",
      "Cost after iteration 40200: 0.315476984208853\n",
      "Train Accuracy after iteration 40200: 99.1625%\n",
      "Test Accuracy after iteration 40200: 44.6%\n",
      "Cost after iteration 40300: 0.2669891104055372\n",
      "Train Accuracy after iteration 40300: 99.5625%\n",
      "Test Accuracy after iteration 40300: 45.4%\n",
      "Cost after iteration 40400: 0.2529872368099775\n",
      "Train Accuracy after iteration 40400: 99.7125%\n",
      "Test Accuracy after iteration 40400: 45.55%\n",
      "Cost after iteration 40500: 0.42105104857678427\n",
      "Train Accuracy after iteration 40500: 96.8625%\n",
      "Test Accuracy after iteration 40500: 44.35%\n",
      "Cost after iteration 40600: 0.2715624344428852\n",
      "Train Accuracy after iteration 40600: 99.55%\n",
      "Test Accuracy after iteration 40600: 45.3%\n",
      "Cost after iteration 40700: 0.2476134875583748\n",
      "Train Accuracy after iteration 40700: 99.7125%\n",
      "Test Accuracy after iteration 40700: 45.5%\n",
      "Cost after iteration 40800: 0.2469880124224713\n",
      "Train Accuracy after iteration 40800: 99.7%\n",
      "Test Accuracy after iteration 40800: 45.65%\n",
      "Cost after iteration 40900: 0.2456366421838714\n",
      "Train Accuracy after iteration 40900: 99.7%\n",
      "Test Accuracy after iteration 40900: 45.45%\n",
      "Cost after iteration 41000: 0.24297047129721183\n",
      "Train Accuracy after iteration 41000: 99.7125%\n",
      "Test Accuracy after iteration 41000: 45.5%\n",
      "Cost after iteration 41100: 0.24011465822773803\n",
      "Train Accuracy after iteration 41100: 99.7375%\n",
      "Test Accuracy after iteration 41100: 45.45%\n",
      "Cost after iteration 41200: 0.3890338903479078\n",
      "Train Accuracy after iteration 41200: 97.875%\n",
      "Test Accuracy after iteration 41200: 42.85%\n",
      "Cost after iteration 41300: 0.2715406772126751\n",
      "Train Accuracy after iteration 41300: 99.5%\n",
      "Test Accuracy after iteration 41300: 45.25%\n",
      "Cost after iteration 41400: 0.24055394658684634\n",
      "Train Accuracy after iteration 41400: 99.725%\n",
      "Test Accuracy after iteration 41400: 45.45%\n",
      "Cost after iteration 41500: 0.23350103710621872\n",
      "Train Accuracy after iteration 41500: 99.75%\n",
      "Test Accuracy after iteration 41500: 45.65%\n",
      "Cost after iteration 41600: 0.23721178844767388\n",
      "Train Accuracy after iteration 41600: 99.7375%\n",
      "Test Accuracy after iteration 41600: 45.35%\n",
      "Cost after iteration 41700: 0.2335120735321002\n",
      "Train Accuracy after iteration 41700: 99.75%\n",
      "Test Accuracy after iteration 41700: 45.35%\n",
      "Cost after iteration 41800: 0.23696758273064178\n",
      "Train Accuracy after iteration 41800: 99.675%\n",
      "Test Accuracy after iteration 41800: 45.5%\n",
      "Cost after iteration 41900: 0.22938281676656805\n",
      "Train Accuracy after iteration 41900: 99.7625%\n",
      "Test Accuracy after iteration 41900: 45.8%\n",
      "Cost after iteration 42000: 0.2260721025121363\n",
      "Train Accuracy after iteration 42000: 99.7875%\n",
      "Test Accuracy after iteration 42000: 45.65%\n",
      "Cost after iteration 42100: 0.2448886471557126\n",
      "Train Accuracy after iteration 42100: 99.6875%\n",
      "Test Accuracy after iteration 42100: 45.55%\n",
      "Cost after iteration 42200: 0.22449635992148556\n",
      "Train Accuracy after iteration 42200: 99.8%\n",
      "Test Accuracy after iteration 42200: 45.4%\n",
      "Cost after iteration 42300: 0.22640313535388285\n",
      "Train Accuracy after iteration 42300: 99.775%\n",
      "Test Accuracy after iteration 42300: 45.25%\n",
      "Cost after iteration 42400: 0.23037479986440504\n",
      "Train Accuracy after iteration 42400: 99.75%\n",
      "Test Accuracy after iteration 42400: 45.5%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 42500: 0.21803765204764225\n",
      "Train Accuracy after iteration 42500: 99.8%\n",
      "Test Accuracy after iteration 42500: 45.45%\n",
      "Cost after iteration 42600: 0.22079742870102045\n",
      "Train Accuracy after iteration 42600: 99.7875%\n",
      "Test Accuracy after iteration 42600: 45.9%\n",
      "Cost after iteration 42700: 0.21749718608391058\n",
      "Train Accuracy after iteration 42700: 99.825%\n",
      "Test Accuracy after iteration 42700: 45.55%\n",
      "Cost after iteration 42800: 0.21439239451184536\n",
      "Train Accuracy after iteration 42800: 99.825%\n",
      "Test Accuracy after iteration 42800: 45.4%\n",
      "Cost after iteration 42900: 0.21704512657213518\n",
      "Train Accuracy after iteration 42900: 99.8%\n",
      "Test Accuracy after iteration 42900: 45.25%\n",
      "Cost after iteration 43000: 0.23570220975052553\n",
      "Train Accuracy after iteration 43000: 99.75%\n",
      "Test Accuracy after iteration 43000: 45.05%\n",
      "Cost after iteration 43100: 0.2108195008184362\n",
      "Train Accuracy after iteration 43100: 99.825%\n",
      "Test Accuracy after iteration 43100: 45.25%\n",
      "Cost after iteration 43200: 0.21032832966400547\n",
      "Train Accuracy after iteration 43200: 99.825%\n",
      "Test Accuracy after iteration 43200: 45.4%\n",
      "Cost after iteration 43300: 0.20768291237320283\n",
      "Train Accuracy after iteration 43300: 99.8375%\n",
      "Test Accuracy after iteration 43300: 45.35%\n",
      "Cost after iteration 43400: 0.2076254603340143\n",
      "Train Accuracy after iteration 43400: 99.8375%\n",
      "Test Accuracy after iteration 43400: 45.55%\n",
      "Cost after iteration 43500: 0.20576084709688172\n",
      "Train Accuracy after iteration 43500: 99.8625%\n",
      "Test Accuracy after iteration 43500: 45.55%\n",
      "Cost after iteration 43600: 0.2024959361122086\n",
      "Train Accuracy after iteration 43600: 99.9%\n",
      "Test Accuracy after iteration 43600: 45.65%\n",
      "Cost after iteration 43700: 0.20161874110384795\n",
      "Train Accuracy after iteration 43700: 99.8875%\n",
      "Test Accuracy after iteration 43700: 45.7%\n",
      "Cost after iteration 43800: 0.20316601338128404\n",
      "Train Accuracy after iteration 43800: 99.875%\n",
      "Test Accuracy after iteration 43800: 46.0%\n",
      "Cost after iteration 43900: 0.19846411461775443\n",
      "Train Accuracy after iteration 43900: 99.8875%\n",
      "Test Accuracy after iteration 43900: 45.7%\n",
      "Cost after iteration 44000: 0.19707590565057642\n",
      "Train Accuracy after iteration 44000: 99.8875%\n",
      "Test Accuracy after iteration 44000: 45.5%\n",
      "Cost after iteration 44100: 0.19889897539005286\n",
      "Train Accuracy after iteration 44100: 99.875%\n",
      "Test Accuracy after iteration 44100: 45.45%\n",
      "Cost after iteration 44200: 0.1950280234511927\n",
      "Train Accuracy after iteration 44200: 99.9125%\n",
      "Test Accuracy after iteration 44200: 45.4%\n",
      "Cost after iteration 44300: 0.19294341231184864\n",
      "Train Accuracy after iteration 44300: 99.9%\n",
      "Test Accuracy after iteration 44300: 45.55%\n",
      "Cost after iteration 44400: 0.19397145655770662\n",
      "Train Accuracy after iteration 44400: 99.9%\n",
      "Test Accuracy after iteration 44400: 45.6%\n",
      "Cost after iteration 44500: 0.19258365157198093\n",
      "Train Accuracy after iteration 44500: 99.9%\n",
      "Test Accuracy after iteration 44500: 45.8%\n",
      "Cost after iteration 44600: 0.18925113628331247\n",
      "Train Accuracy after iteration 44600: 99.8875%\n",
      "Test Accuracy after iteration 44600: 45.45%\n",
      "Cost after iteration 44700: 0.18980264779416342\n",
      "Train Accuracy after iteration 44700: 99.9125%\n",
      "Test Accuracy after iteration 44700: 45.4%\n",
      "Cost after iteration 44800: 0.18881280916750953\n",
      "Train Accuracy after iteration 44800: 99.925%\n",
      "Test Accuracy after iteration 44800: 45.45%\n",
      "Cost after iteration 44900: 0.18550350971605611\n",
      "Train Accuracy after iteration 44900: 99.9125%\n",
      "Test Accuracy after iteration 44900: 45.5%\n",
      "Cost after iteration 44999: 0.18586440064083337\n",
      "Train Accuracy after iteration 44999: 99.9125%\n",
      "Test Accuracy after iteration 44999: 45.5%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters, costs = L_LayeredModel(X_train, Y_train, [X_train.shape[0],256,10], learning_rate=0.025, num_iterations = 45000, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "68184570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6, 3, 6, 0, 6, 0, 6, 6, 9], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_bonus = predict(X_test_bonus, parameters)\n",
    "Y_test_bonus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
